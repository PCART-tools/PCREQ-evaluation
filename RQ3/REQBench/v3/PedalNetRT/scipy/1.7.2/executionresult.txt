GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]

  | Name    | Type    | Params
------------------------------------
0 | wavenet | WaveNet | 10.6 K
------------------------------------
10.6 K    Trainable params
0         Non-trainable params
10.6 K    Total params
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.90it/s]                                                                      /home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule
  warnings.warn(*args, **kwargs)
/home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/24 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s] Epoch 0:   4%|â–         | 1/24 [00:00<00:06,  3.66it/s]Epoch 0:   4%|â–         | 1/24 [00:00<00:06,  3.66it/s, loss=6.11, v_num=752]Epoch 0:   8%|â–Š         | 2/24 [00:00<00:03,  6.37it/s, loss=90.5, v_num=752]Epoch 0:  12%|â–ˆâ–Ž        | 3/24 [00:00<00:02,  8.46it/s, loss=60.8, v_num=752]Epoch 0:  17%|â–ˆâ–‹        | 4/24 [00:00<00:01, 10.14it/s, loss=60.8, v_num=752]Epoch 0:  17%|â–ˆâ–‹        | 4/24 [00:00<00:01, 10.14it/s, loss=46, v_num=752]  Epoch 0:  21%|â–ˆâ–ˆ        | 5/24 [00:00<00:02,  8.29it/s, loss=37.1, v_num=752]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:00<00:01,  9.34it/s, loss=60.7, v_num=752]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 7/24 [00:00<00:01, 10.26it/s, loss=60.7, v_num=752]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 7/24 [00:00<00:01, 10.26it/s, loss=73.9, v_num=752]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:00<00:01, 11.10it/s, loss=76.9, v_num=752]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:00<00:01, 11.82it/s, loss=68.4, v_num=752]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:00<00:01, 12.49it/s, loss=68.4, v_num=752]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:00<00:01, 12.49it/s, loss=63, v_num=752]  Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:00<00:00, 13.10it/s, loss=57.4, v_num=752]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:00<00:00, 13.68it/s, loss=60.3, v_num=752]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:00<00:00, 14.18it/s, loss=60.3, v_num=752]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:00<00:00, 14.18it/s, loss=63.1, v_num=752]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:00<00:00, 14.66it/s, loss=73.1, v_num=752]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [00:00<00:00, 15.09it/s, loss=69.3, v_num=752]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:01<00:00, 15.51it/s, loss=69.3, v_num=752]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:01<00:00, 15.50it/s, loss=66.5, v_num=752]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:01<00:00, 15.89it/s, loss=62.7, v_num=752]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:01<00:00, 15.26it/s, loss=59.2, v_num=752]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:01<00:00, 16.08it/s, loss=59.2, v_num=752]
Validating: 0it [00:00, ?it/s][A
Validating:  17%|â–ˆâ–‹        | 1/6 [00:00<00:01,  4.48it/s][AEpoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:01<00:00, 15.47it/s, loss=59.2, v_num=752]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.33it/s, loss=59.2, v_num=752]
                                                         [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.30it/s, loss=59.2, v_num=752]
