GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]

  | Name    | Type    | Params
------------------------------------
0 | wavenet | WaveNet | 10.6 K
------------------------------------
10.6 K    Trainable params
0         Non-trainable params
10.6 K    Total params
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.06it/s]                                                                      /home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule
  warnings.warn(*args, **kwargs)
/home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/24 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s] Epoch 0:   4%|â–         | 1/24 [00:00<00:05,  4.30it/s]Epoch 0:   4%|â–         | 1/24 [00:00<00:05,  4.30it/s, loss=7.44, v_num=750]Epoch 0:   8%|â–Š         | 2/24 [00:00<00:03,  7.27it/s, loss=5.82, v_num=750]Epoch 0:  12%|â–ˆâ–Ž        | 3/24 [00:00<00:02,  9.44it/s, loss=191, v_num=750] Epoch 0:  17%|â–ˆâ–‹        | 4/24 [00:00<00:01, 11.10it/s, loss=191, v_num=750]Epoch 0:  17%|â–ˆâ–‹        | 4/24 [00:00<00:01, 11.10it/s, loss=144, v_num=750]Epoch 0:  21%|â–ˆâ–ˆ        | 5/24 [00:00<00:01, 12.48it/s, loss=120, v_num=750]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:00<00:01, 13.63it/s, loss=101, v_num=750]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 7/24 [00:00<00:01, 14.59it/s, loss=101, v_num=750]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 7/24 [00:00<00:01, 14.58it/s, loss=86.7, v_num=750]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [00:00<00:01, 15.47it/s, loss=130, v_num=750] Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:00<00:00, 16.21it/s, loss=151, v_num=750]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:00<00:00, 16.89it/s, loss=151, v_num=750]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:00<00:00, 16.88it/s, loss=136, v_num=750]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:00<00:00, 17.46it/s, loss=124, v_num=750]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:00<00:00, 17.99it/s, loss=116, v_num=750]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:00<00:00, 18.45it/s, loss=116, v_num=750]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:00<00:00, 18.44it/s, loss=107, v_num=750]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:00<00:00, 18.86it/s, loss=110, v_num=750]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [00:00<00:00, 19.23it/s, loss=103, v_num=750]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:00<00:00, 19.58it/s, loss=103, v_num=750]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:00<00:00, 19.57it/s, loss=96.2, v_num=750]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:00<00:00, 19.87it/s, loss=90.6, v_num=750]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:00<00:00, 18.52it/s, loss=85.6, v_num=750]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:00<00:00, 19.48it/s, loss=85.6, v_num=750]
Validating: 0it [00:00, ?it/s][A
Validating:  17%|â–ˆâ–‹        | 1/6 [00:00<00:02,  2.49it/s][AEpoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:01<00:00, 15.78it/s, loss=85.6, v_num=750]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.82it/s, loss=85.6, v_num=750]
                                                         [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.79it/s, loss=85.6, v_num=750]
