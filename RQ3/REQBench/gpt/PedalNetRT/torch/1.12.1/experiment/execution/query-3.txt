
                        **Debug Mission** 
                        Resolve runtime crash caused by code-level incompatibilities in dependency chain.

                        **Input Context**
                        - Current environment: absl-py==2.1.0
cachetools==5.3.1
charset-normalizer==3.3.0
cycler==0.11.0
dataclasses==0.6
fsspec==2023.1.0
future==1.0.0
google-auth==2.20.0
google-auth-oauthlib==0.4.4
grpcio==1.52.0
idna==3.4
importlib-metadata==6.7.0
kiwisolver==1.4.5
Markdown==3.4.3
MarkupSafe==2.1.2
matplotlib==3.3.3
numpy==1.20.0
oauthlib==3.2.1
Pillow==9.4.0
protobuf==3.19.4
pyasn1==0.5.0
pyasn1-modules==0.3.0
pyparsing==3.1.1
python-dateutil==2.9.0
pytorch-lightning==1.7.8
PyYAML==5.4.1
requests==2.31.0
requests-oauthlib==1.3.1
rsa==4.7.2
scipy==1.7.1
six==1.16.0
tensorboard==2.11.0
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.0
torch==1.12.1
tqdm==4.66.1
typing_extensions==4.3.0
urllib3==1.26.16
Werkzeug==2.2.2
zipp==3.11.0

                        - Python version: 3.7
                        - Project source code: import pytorch_lightning as pl
import argparse
import sys

from model import PedalNet
from prepare import prepare


def main(args):
    """
    This trains the PedalNet model to match the output data from the input data.

    When you resume training from an existing model, you can override hparams such as
        max_epochs, batch_size, or learning_rate. Note that changing num_channels,
        dilation_depth, num_repeat, or kernel_size will change the shape of the WaveNet
        model and is not advised.

    """

    prepare(args)
    model = PedalNet(vars(args))
    trainer = pl.Trainer(
        resume_from_checkpoint=args.model if args.resume else None,
        gpus=None if args.cpu or args.tpu_cores else args.gpus,
        tpu_cores=args.tpu_cores,
        log_every_n_steps=100,
        max_epochs=args.max_epochs,
    )

    trainer.fit(model)
    trainer.save_checkpoint(args.model)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("in_file", nargs="?", default="data/in.wav")
    parser.add_argument("out_file", nargs="?", default="data/out.wav")
    parser.add_argument("--sample_time", type=float, default=100e-3)

    parser.add_argument("--num_channels", type=int, default=12)
    parser.add_argument("--dilation_depth", type=int, default=10)
    parser.add_argument("--num_repeat", type=int, default=1)
    parser.add_argument("--kernel_size", type=int, default=3)

    parser.add_argument("--batch_size", type=int, default=64)
    parser.add_argument("--learning_rate", type=float, default=3e-3)

    parser.add_argument("--max_epochs", type=int, default=1)
    parser.add_argument("--gpus", type=int, default=1)
    parser.add_argument("--tpu_cores", type=int, default=None)
    parser.add_argument("--cpu", action="store_true")

    parser.add_argument("--model", type=str, default="models/pedalnet/pedalnet.ckpt")
    parser.add_argument("--resume", action="store_true")
    args = parser.parse_args()
    main(args)

                        - library source code: 
                        - PyPI metadata (including version constraints): ['typing-extensions']
                        - Crash traceback: Traceback (most recent call last):
  File "train.py", line 1, in <module>
    import pytorch_lightning as pl
ModuleNotFoundError: No module named 'pytorch_lightning'


                        **Analysis Protocol**
                        1. Traceback Pattern Matching：
                        a. Identify error type (ImportError/AttributeError/TypeError)
                        b. Map to possible API changes in torch v1.12.1 or its dependencies
                        2. Compatibility Matrix Check：
                        a. Verify library-to-library API compatibility through version ranges
                        b. Confirm project-to-library interface compatibility
                        3. Breakpoint Isolation：
                        b. Determine if conflict originates from：
                            • Direct API changes in torch
                            • Transitive dependency API shifts

                        **Resolution Rules**
                        - PRIMARY CONSTRAINT: Maintain torch==1.12.1
                        - SECONDARY ADJUSTMENTS: 
                        • Modify dependency versions only when API contracts allow
                        • Prefer backward-compatible minor version changes

                        **Output Mandates**
                        STRICT FORMAT:
                        lib1==x.y.z  
                        lib2==a.b.c
                        ...
                        PROHIBITED:
                        • Any non-version text.
                        • Library additions/removals
                        • Version placeholders
                        MANDATORY:
                        • Preserve original library names and count
                        • Pin EXACT versions
                        • Zero explanations/comments
                        